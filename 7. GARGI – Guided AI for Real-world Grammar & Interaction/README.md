# GARGI â€” Guided AI for Real-world General Interaction

GARGI is an explainable, offline-first AI system designed to evaluate spoken responses and provide actionable feedback for **real-world spoken communication**.

The project focuses on **general interaction** rather than exam-specific scoring, helping users improve clarity, fluency, grammar, and topic alignment in everyday conversations, academic discussions, interviews, and professional settings.

---

## ğŸ” Key Capabilities

- ğŸ™ï¸ **Speech Input & Transcription**
  - Local audio recording
  - Speech-to-text using Whisper

- ğŸ—£ï¸ **Fluency Analysis**
  - Speaking rate (WPM)
  - Pause ratio
  - Filler word detection

- âœï¸ **Grammar Analysis**
  - Rule-based grammar checking via LanguageTool
  - Error density and explainable grammar feedback

- ğŸ¯ **Topic Relevance & Alignment**
  - Semantic similarity using Sentence Transformers
  - Concept-level coverage analysis
  - Sentence-level on-topic ratio
  - Explainable relevance diagnostics

- ğŸ§  **Explainability & Trust Layer**
  - Transparent scoring logic
  - Evidence-based feedback
  - XAI-inspired scoring traces

- ğŸ“ˆ **Learning-Oriented Feedback**
  - Priority improvement suggestions
  - Coaching-style guidance
  - Reflection prompts for self-assessment

---

## ğŸ§© System Architecture


---

## ğŸ› ï¸ Technology Stack

- Python 3.10 / 3.13
- Whisper (speech-to-text)
- LanguageTool (grammar analysis)
- Sentence Transformers (`all-mpnet-base-v2`)
- YAKE (keyword extraction)
- NumPy, SciPy, scikit-learn

All components are **free**, **local-first**, and compatible with **Windows**.

---

## ğŸš€ Running the Project

1. Install dependencies:
   ```bash
   pip install -r requirements.txt

2. Start LanguageTool server:
    java -jar languagetool-server.jar --port 8081

3. Run GARGI:
    python main.py
